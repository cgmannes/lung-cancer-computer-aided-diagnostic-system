# -*- coding: utf-8 -*-
"""cancerCAD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_4hJCUOGuyptg-_tVx8HXPkl9mQy6tQU
"""

# Import libraries.
import os 
import pickle 
import numpy as np 
import h5py as hp 
import tensorflow as tf 
import matplotlib.pyplot as plt 

from numpy import newaxis 
from keras import models 
from keras import layers 
from keras import optimizers 
from keras import regularizers 
from keras.models import Model 
from keras.utils import to_categorical 
from sklearn.model_selection import train_test_split 
from keras.preprocessing.image import ImageDataGenerator 
from keras.applications.inception_v3 import preprocess_input
from keras.layers import GlobalAveragePooling2D, Dense, Dropout
from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler
                          
from google.colab import drive 
drive.mount('/content/drive') 

# Verify use of GPU (in Tensorflow)
tf.test.gpu_device_name()

#'''
# Location of files.
dirName = "drive/My Drive/cs680_pickle_data"

# Open and load label data.
f_label = open(dirName + '/' + 'labels_vector4', 'r')
labels = pickle.load(f_label)
f_label.close()

# Lenth for additional dimension.
N = labels.shape[0]

# Initialize Nx32x32 array correctly orientated for train_test_split.
X = np.zeros([N,32,32] , dtype = np.float32) # cos 32x32 pixel images

# Open and load 32x32 cnn image data. 
f_imgs = open(dirName + '/' + 'cnn_imgs' )
cnn_imgs = pickle.load(f_imgs)
f_imgs.close()

# Populate X with cnn images.
for i in range(N):
  X[i,:,:] = cnn_imgs[:,:,i]

# Split the dataset into training, validation, and testing subsets. 
X_train, X_test, y_train, y_test = train_test_split(X, labels[0:N], test_size=0.30, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.50, random_state=30)

# Test plot.
plt.figure()
plt.imshow(X_val[80,:,:], cmap=plt.get_cmap('gray'))

# Copy image data for VGG16.
X_train3 = X_train.copy()
X_val3 = X_val.copy()
X_test3 = X_test.copy()

# Convert 3D data array to 4D tensor with 3 channels, (Fake RGB).
X_train3 = np.repeat(X_train3[..., np.newaxis], 3, -1)
X_val3 = np.repeat(X_val3[..., np.newaxis], 3, -1)
X_test3 = np.repeat(X_test3[..., np.newaxis], 3, -1)

# Test plot.
plt.figure()
plt.imshow(X_train3[80,:,:,2], cmap=plt.get_cmap('gray'))

# Convert label vectors to matrices.
y_train = to_categorical(y_train)
y_val = to_categorical(y_val)
y_test = to_categorical(y_test)

# Save imported data.
np.save(dirName + '/X_train.npy' , X_train)
np.save(dirName + '/X_val.npy' , X_val)
np.save(dirName + '/X_test.npy' , X_test)
#'''

# Imported npy data files.
#X_train = np.load(dirName + '/X_train.npy')
#X_val = np.load(dirName + '/X_val.npy')
#X_test = np.load(dirName + '/X_test.npy')
print(y_train.shape)

# Define and configure ImageDataGenerator for training data.
train_datagen = ImageDataGenerator(
    rotation_range = 180,
    width_shift_range = 0.15,
    height_shift_range = 0.15,
    horizontal_flip = True,
    vertical_flip = True,
    zca_whitening = True)

# Define and configure ImageDataGenerator for validation data.
val_datagen = ImageDataGenerator()

'''
# Code for displaying the augemented image from train_datagen.

# Directory to save augmented images.
aug_imgs = "drive/My Drive/cs680_aug_images"


for X_batch, y_batch in train_datagen.flow(X_train, y_train,
                                           batch_size = 9,
                                           save_to_dir = aug_imgs,
                                           save_prefix = 'aug',
                                           save_format='png'):
  
	# create a grid of 3x3 images
	for i in range(0, 9):
		plt.subplot(330 + 1 + i)
		plt.imshow(X_batch[i].reshape(32, 32), cmap=plt.get_cmap('gray'))
    
	# show the plot
	plt.show()
	break
'''

# Define the batch size by calling the flow function.
train_generator = train_datagen.flow(X_train , y_train , batch_size = 32)
val_generator = val_datagen.flow(X_val , y_val , batch_size = 32)

def calc_metrics(label , pred):
  '''
  This function calculates various measures commonly
  employed in machine learning.
  '''
  # Label 1 indicates malignant and label 0 indicates benign.
  # Initialize quantities to 0.
  TP = TN = FP = FN = 0
    
  for true_label , pred_label in zip(label , pred):
    if true_label == pred_label:
      if true_label == 1:
        TP += 1
      else:
        TN += 1
    else:
      if true_label == 1:
        FP += 1
      else:
        FN += 1
                
  assert((TP + FP + TN + FN) == len(pred))
  
  # Calculate the desired quantities.
  precision = float(TP)/(TP + FP)
  recall = float(TP)/(TP + FN)
  accuracy = (float(TP + TN))/(TP + FP + TN + FN)
  sensitivity = float(TP)/(TP + FN)
  specificity = float(TN)/(TN + FP)
    
    
  return precision , recall , accuracy , sensitivity , specificity

from keras.applications.vgg16 import VGG16

# Base architecture of VGG16.
conv_base16 = VGG16(weights = 'imagenet',
                    include_top = False,
                    input_shape=(32,32,3) )


model_16 = models.Sequential()
model_16.add(conv_base16)
model_16.add(layers.Flatten())
model_16.add(layers.Dense(4000, activation = 'relu'))
model_16.add(layers.Dense(4000, activation = 'relu'))
model_16.add(layers.Dense(2, activation = 'softmax'))

model_16.compile(optimizer = optimizers.RMSprop(lr=1e-5),
                 loss='categorical_crossentropy',
                 metrics=['acc'])

model_16.summary()

with tf.device('/device:GPU:0'):
  history_16 = model_16.fit_generator(train_generator3,
                                      steps_per_epoch = len(X_train3)/32,
                                      validation_steps = 30,
                                      validation_data = val_generator3,
                                      shuffle = True,
                                      epochs = 25)

#model.save('drive/My Drive/cs680_pickle_data/vgg16.h5')

# Extract accuracy and loss for plotting.
acc_16 = history_16.history['acc']
val_acc_16 = history_16.history['val_acc']
loss_16 = history_16.history['loss']
val_loss_16 = history_16.history['val_loss']

epochs = range(1, len(acc_16) + 1)

plt.figure()
plt.plot(epochs, acc_16 , 'm', label='Training Accuracy')
plt.plot(epochs, val_acc_16 , 'b', label='Validation Accuracy')
plt.title('Training and Validation Accuracy for VGG 16 \n Network with Split Vote' , size = 20)
plt.xlabel('Number of Epochs' , size = 20)
plt.ylabel('Accuracy (Fraction)' , size = 20)
plt.legend()

plt.figure()
plt.plot(epochs, loss_16 , 'm', label='Training Loss')
plt.plot(epochs, val_loss_16 , 'b', label='Validation Loss')
plt.title('Training and Validation Loss for VGG 16 \n Network with Split Vote' , size = 20)
plt.xlabel('Number of Epochs', size = 20)
plt.ylabel('Loss' , size = 20)
plt.legend()

plt.show()

vgg16_pred = model_16.predict_classes(X_test3)

# Calculate metrics for test data.
precision , recall , accuracy , sensitivity , specificity = calc_metrics(y_test[:,1] , vgg16_pred)

print("< Test Set Metrics >")
print('\tprecision - ', round(precision, 4)) 
print('\trecall - ', round(recall, 4)) 
print('\taccuracy - ', round(accuracy, 4)) 
print('\tsensitivity - ', round(sensitivity, 4)) 
print('\tspecificity - ', round(specificity, 4))
